{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "import dynaphos\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "from dynaphos.simulator import GaussianSimulator as PhospheneSimulator\n",
    "from dynaphos import cortex_models\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from utils import resize\n",
    "\n",
    "import local_datasets\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from utils import (\n",
    "    CustomSummaryTracker,\n",
    "    dilation3x3,\n",
    "    resize,\n",
    "    tensor_to_rgb,\n",
    "    undo_standardize,\n",
    ")\n",
    "\n",
    "import importlib\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'local_datasets' from 'c:\\\\Users\\\\appel\\\\Documents\\\\Project\\\\Dynaphos\\\\viseon\\\\local_datasets.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(local_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(yaml_file):\n",
    "    with open(yaml_file) as file:\n",
    "        raw_content = yaml.load(file,Loader=yaml.FullLoader) # nested dictionary\n",
    "    return {k:v for params in raw_content.values() for k,v in params.items()} # unpacked\n",
    "\n",
    "cfg = load_config('../_config/exp-local/faces_boundary_supervised_phosphenes_no_decoder.yaml')\n",
    "cfg['retinal_compression'] = True\n",
    "cfg['data_directory'] = '../../data/face/LaPa'\n",
    "cfg['base_config'] = '../_config/exp-local/params.yaml'\n",
    "cfg['phosphene_map'] = '../_config/phosphene_maps/DefaultCoordinateMap_1000_phosphenes.pickle'\n",
    "cfg['batch_size'] = 1\n",
    "cfg['fov'] = 5\n",
    "cfg['resolution'] = [256, 256]\n",
    "cfg['output_scaling'] = 1.e-4\n",
    "cfg['n_electrodes'] = 1024\n",
    "params = dynaphos.utils.load_params(cfg['base_config'])\n",
    "params['run']['batch_size'] = cfg['batch_size']\n",
    "\n",
    "cfg['retinal_compression'] = True\n",
    "cfg['imsize'] = [64, 64]\n",
    "cfg['fov'] = 16\n",
    "cfg['circular_mask'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = local_datasets.get_lapa_dataset(cfg)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=cfg['batch_size'], shuffle=True, drop_last=True)\n",
    "valloader = DataLoader(valset, batch_size=cfg['batch_size'], shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_batch = next(iter(valloader))\n",
    "\n",
    "plt.imshow(example_batch['image'][0].permute(1,2,0).cpu())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_simulator(cfg, phosphene_coords=None):\n",
    "    # initialise simulator\n",
    "\n",
    "    params = dynaphos.utils.load_params(cfg['base_config'])\n",
    "    params['run']['batch_size'] = cfg['batch_size']\n",
    "\n",
    "    if phosphene_coords is None:\n",
    "        n_phosphenes = cfg['n_electrodes']\n",
    "        phosphene_coords = cortex_models.get_visual_field_coordinates_probabilistically(params, n_phosphenes)\n",
    "\n",
    "    simulator = PhospheneSimulator(params, phosphene_coords)\n",
    "    return simulator\n",
    "\n",
    "n_phosphenes = cfg['n_electrodes']\n",
    "params = dynaphos.utils.load_params(cfg['base_config'])\n",
    "params['batch_size'] = 4\n",
    "phosphene_coords = cortex_models.get_visual_field_coordinates_probabilistically(params, n_phosphenes)\n",
    "simulator = get_simulator(cfg, phosphene_coords=phosphene_coords)\n",
    "cfg['SPVsize'] = simulator.phosphene_maps.shape[-2:]\n",
    "len(simulator.phosphene_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phosphene map size: torch.Size([256, 256])\n",
      "Number of phosphenes: 1024\n"
     ]
    }
   ],
   "source": [
    "cfg['SPVsize'] = simulator.phosphene_maps.shape[-2:]\n",
    "print(f\"Phosphene map size: {cfg['SPVsize']}\")\n",
    "N_PHOSPHENES = simulator.num_phosphenes\n",
    "print(f\"Number of phosphenes: {N_PHOSPHENES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = phosphene_coords._x, phosphene_coords._y\n",
    "coords = torch.Tensor(np.array([x, y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_square = np.sqrt(N_PHOSPHENES)\n",
    "\n",
    "# if the sqrt is not an integer, we need to find the closest integer that is bigger\n",
    "if int(reshape_square) != reshape_square:\n",
    "    reshape_square = int(reshape_square) + 1\n",
    "else:\n",
    "    reshape_square = int(reshape_square)\n",
    "    \n",
    "reshape_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5220defb314f40368b109754f86cb33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Shift X', max=0.5, min=-0.5, step=0.001), FloatSlide…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to update the plot based on the slider values\n",
    "def update_plot(shift_x=0.5, shift_y=0.5, scale=20):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    shifted_image = torch.roll(face_image, int(shift_x * face_image.shape[-1]), dims=-1)\n",
    "    shifted_image = torch.roll(shifted_image, int(shift_y * face_image.shape[-2]), dims=-2)\n",
    "    \n",
    "    # scale content and fit into original image size\n",
    "    if scale > 0 and scale < 1.:\n",
    "        scaled_image = F.interpolate(shifted_image, scale_factor=scale, mode='nearest')\n",
    "        shifted_image = torch.zeros((1, 1, *cfg['imsize']), device=cfg['device'])\n",
    "        shifted_image[0, 0, \n",
    "                    int((cfg['imsize'][0] - scaled_image.shape[-2]) / 2):int((cfg['imsize'][0] + scaled_image.shape[-2]) / 2), \n",
    "                    int((cfg['imsize'][1] - scaled_image.shape[-1]) / 2):int((cfg['imsize'][1] + scaled_image.shape[-1]) / 2)] = scaled_image\n",
    "    elif scale == 0.: # no scaling\n",
    "        shifted_image = torch.zeros((1, 1, *cfg['imsize']), device=cfg['device'])\n",
    "    elif scale > 1.:\n",
    "        scaled_image = F.interpolate(shifted_image, scale_factor=scale, mode='nearest')\n",
    "        # crop\n",
    "        shifted_image = scaled_image[:, :,\n",
    "                    int((scaled_image.shape[-2] - cfg['imsize'][0]) / 2):int((scaled_image.shape[-2] + cfg['imsize'][0]) / 2),\n",
    "                    int((scaled_image.shape[-1] - cfg['imsize'][1]) / 2):int((scaled_image.shape[-1] + cfg['imsize'][1]) / 2)]\n",
    "        \n",
    "    # Update the visual input display\n",
    "    ax[0].imshow(shifted_image[0].permute(1,2,0).cpu().numpy(), cmap='gray')\n",
    "    ax[0].set_title('Visual Input')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    # Update the phosphene display\n",
    "    resized_image = resize(shifted_image, cfg['SPVsize'], interpolation='nearest')\n",
    "    stimulation = simulator.sample_centers(resized_image.mean(1, keepdim=True)) * cfg['output_scaling']\n",
    "    simulator.reset()\n",
    "    phosphenes = simulator(stimulation).unsqueeze(1)\n",
    "    \n",
    "    ax[1].imshow(phosphenes.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "    ax[1].set_title('Phosphenes')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    # Update the stimulation display\n",
    "    stimulation_square = torch.zeros((reshape_square, reshape_square), device=cfg['device'])\n",
    "    stimulation_square.view(-1)[:N_PHOSPHENES] = stimulation\n",
    "\n",
    "    ax[2].imshow(stimulation_square.cpu().numpy(), cmap='gray')\n",
    "    ax[2].set_title('Stimulation')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate the circle image with the specified size\n",
    "face_image = example_batch['contour'].to(cfg['device'])\n",
    "face_image = dilation3x3(face_image)\n",
    "\n",
    "# Display the interactive widgets\n",
    "plot = interact(update_plot, \n",
    "         shift_x=FloatSlider(min=-0.5, max=0.5, step=0.001, value=0., description='Shift X'), \n",
    "         shift_y=FloatSlider(min=-0.5, max=0.5, step=0.001, value=0., description='Shift Y'),\n",
    "         scale=FloatSlider(min=0.0, max=3.0, step=0.001, value=1., description='Scale'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.DoG import DoGConv2DLayer, DoGConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out size: torch.Size([1, 1024])\n",
      "tensor(3.5384e-05, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.9472e-05, device='cuda:0', grad_fn=<MaxBackward1>) \n",
      "\n",
      "Retinal Encoder Parameters: 5351208\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, n_channels, stride=1, resample_out=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, n_channels,kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(n_channels, n_channels,kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(n_channels)\n",
    "        self.resample_out = resample_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        if self.resample_out:\n",
    "            out = self.resample_out(out)\n",
    "        return out\n",
    "    \n",
    "def convlayer(n_input, n_output, k_size=3, stride=1, padding=1, resample_out=None):\n",
    "    layer = [\n",
    "        nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(n_output),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        resample_out]\n",
    "    if resample_out is None:\n",
    "        layer.pop()\n",
    "    return layer\n",
    "\n",
    "class Retinal_Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, n_electrodes=1024, out_scaling=1e-4, out_activation='relu'):\n",
    "        super(Retinal_Encoder, self).__init__()\n",
    "        self.output_scaling = out_scaling\n",
    "        self.out_activation = {'tanh': nn.Tanh(), ## NOTE: simulator expects only positive stimulation values \n",
    "                               'sigmoid': nn.Sigmoid(),\n",
    "                               'relu': nn.ReLU(),\n",
    "                               'softmax':nn.Softmax(dim=1)}[out_activation]\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "                                    *convlayer(in_channels,8,3,1,1),\n",
    "                                    *convlayer(8,16,3,2,1),\n",
    "                                    *convlayer(16,32,3,2,1),\n",
    "                                    *convlayer(32,64,3,2,1),\n",
    "                                    *convlayer(64,128,3,2,1),\n",
    "                                    *convlayer(128,256,3,2,1),\n",
    "                                    *convlayer(256,512,3,2,1),\n",
    "                                    *convlayer(512,1024,3,1,1),\n",
    "                                    nn.AvgPool2d(2),\n",
    "                                    self.out_activation\n",
    "                                   )\n",
    "        \n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "                                    *convlayer(in_channels,8,3,2,1),\n",
    "                                    # *convlayer(8,16,3,2,1),\n",
    "                                    *convlayer(8,32,3,2,1),\n",
    "                                    # *convlayer(32,64,3,2,1),\n",
    "                                    *convlayer(32,128,3,2,1),\n",
    "                                    # *convlayer(128,256,3,2,1),\n",
    "                                    *convlayer(128,512,3,2,1),\n",
    "                                    *convlayer(512,1024,3,2,1),\n",
    "                                    nn.AvgPool2d(2),\n",
    "                                    self.out_activation\n",
    "                                   )\n",
    "\n",
    "        # self.model = nn.Sequential(*convlayer(in_channels,8,3,1,1),\n",
    "        #                            *convlayer(8,16,3,1,1,resample_out=nn.MaxPool2d(2)),\n",
    "        #                            *convlayer(16,32,3,1,1,resample_out=nn.MaxPool2d(2)),\n",
    "        #                            ResidualBlock(32, resample_out=None),\n",
    "        #                            ResidualBlock(32, resample_out=None),\n",
    "        #                            ResidualBlock(32, resample_out=None),\n",
    "        #                            ResidualBlock(32, resample_out=None),\n",
    "        #                            *convlayer(32,16,3,1,1),\n",
    "        #                            nn.Conv2d(16,1,3,1,1),\n",
    "        #                            nn.Flatten(),\n",
    "        #                            nn.Linear(256,n_electrodes),\n",
    "        #                            self.out_activation)\n",
    "            \n",
    "        \n",
    "        self.n_electrodes = n_electrodes\n",
    "        self.fc = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        stimulation = self.model(x)\n",
    "        return stimulation.squeeze(-1).squeeze(-1) * self.output_scaling\n",
    "\n",
    "\n",
    "retinal_encoder = Retinal_Encoder(n_electrodes=cfg['n_electrodes'], out_scaling=cfg['output_scaling'], out_activation='relu').to(cfg['device'])\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "# test forward pass\n",
    "output = retinal_encoder(torch.randn(1, 3, 64, 64).to(cfg['device']))\n",
    "\n",
    "print('out size:', output.shape)\n",
    "print(output.min(), output.max(), '\\n')\n",
    "\n",
    "# count number of parameters\n",
    "print('Retinal Encoder Parameters:', sum(p.numel() for p in retinal_encoder.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([1, 3, 64, 64])\n",
      "1.62 ms ± 71 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "0.9813308715820312 ms\n",
      "Retinal Encoder Parameters: 5351208\n"
     ]
    }
   ],
   "source": [
    "retinal_encoder = Retinal_Encoder(n_electrodes=cfg['n_electrodes'], out_scaling=cfg['output_scaling'], out_activation='relu').to(cfg['device'])\n",
    "\n",
    "input = torch.randn(1, 3, 64, 64).to(cfg['device'])\n",
    "\n",
    "# Warm up the model (optional but recommended for more accurate timing)\n",
    "for _ in range(10):\n",
    "    _ = retinal_encoder(input)\n",
    "\n",
    "def forward_pass():\n",
    "    torch.cuda.synchronize()\n",
    "    _ = retinal_encoder(input)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# time test \n",
    "\n",
    "start = time()\n",
    "retinal_encoder(input)\n",
    "end = time()\n",
    "\n",
    "# print the input size, network architecture, time taken for forward pass, and number of parameters\n",
    "print('Input size:', input.shape)\n",
    "# print(retinal_encoder)\n",
    "%timeit forward_pass()\n",
    "print((end - start) * 1000, 'ms')\n",
    "print('Retinal Encoder Parameters:', sum(p.numel() for p in retinal_encoder.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaap's encoder\n",
    "Input size: torch.Size([1, 3, 128, 128]) \\\n",
    "3.72 ms ± 328 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) \\\n",
    "5.002737045288086 ms \\\n",
    "Retinal Encoder Parameters: 1134969\n",
    "\n",
    "Input size: torch.Size([1, 3, 64, 64]) \\\n",
    "4.11 ms ± 499 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) \\\n",
    "3.983736038208008 ms \\\n",
    "Retinal Encoder Parameters: 348537\n",
    "\n",
    "### Fully conv encoder\n",
    "Input size: torch.Size([1, 3, 128, 128]) \\\n",
    "2.7 ms ± 293 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) \\\n",
    "2.0041465759277344 ms \\\n",
    "Retinal Encoder Parameters: 6295368\n",
    "\n",
    "Input size: torch.Size([1, 3, 64, 64]) \\\n",
    "1.62 ms ± 71 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each) \\\n",
    "0.9813308715820312 ms \\\n",
    "Retinal Encoder Parameters: 5351208\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small round of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 4.00 GiB total capacity; 3.29 GiB already allocated; 0 bytes free; 3.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [456], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m retinal_encoder\u001b[38;5;241m.\u001b[39mto(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m phosphene_coords \u001b[38;5;241m=\u001b[39m cortex_models\u001b[38;5;241m.\u001b[39mget_visual_field_coordinates_probabilistically(params, n_phosphenes)\n\u001b[1;32m---> 11\u001b[0m simulator \u001b[38;5;241m=\u001b[39m \u001b[43mget_simulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphosphene_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Define loss function\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n",
      "Cell \u001b[1;32mIn [332], line 11\u001b[0m, in \u001b[0;36mget_simulator\u001b[1;34m(cfg, phosphene_coords)\u001b[0m\n\u001b[0;32m      8\u001b[0m     n_phosphenes \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_electrodes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     phosphene_coords \u001b[38;5;241m=\u001b[39m cortex_models\u001b[38;5;241m.\u001b[39mget_visual_field_coordinates_probabilistically(params, n_phosphenes)\n\u001b[1;32m---> 11\u001b[0m simulator \u001b[38;5;241m=\u001b[39m \u001b[43mPhospheneSimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphosphene_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m simulator\n",
      "File \u001b[1;32mc:\\Users\\appel\\anaconda3\\envs\\ML\\lib\\site-packages\\dynaphos\\simulator.py:188\u001b[0m, in \u001b[0;36mGaussianSimulator.__init__\u001b[1;34m(self, params, coordinates, rng, theta)\u001b[0m\n\u001b[0;32m    183\u001b[0m set_deterministic(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeg2pix_coeff \u001b[38;5;241m=\u001b[39m get_deg2pix_coeff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphosphene_maps \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_phosphene_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\appel\\anaconda3\\envs\\ML\\lib\\site-packages\\dynaphos\\simulator.py:307\u001b[0m, in \u001b[0;36mGaussianSimulator.generate_phosphene_maps\u001b[1;34m(self, coordinates, remove_invalid, theta)\u001b[0m\n\u001b[0;32m    305\u001b[0m     phosphene_maps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgabor_rotation(x, y, theta)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     phosphene_maps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m phosphene_maps\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 4.00 GiB total capacity; 3.29 GiB already allocated; 0 bytes free; 3.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "cfg['batch_size'] = 2\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=cfg['batch_size'], shuffle=True, drop_last=True)\n",
    "\n",
    "# Initialize the retinal encoder\n",
    "cfg['output_scaling'] = 0.0002\n",
    "retinal_encoder = Retinal_Encoder(out_activation='relu', in_channels=3, n_electrodes=cfg['n_electrodes'], out_scaling=cfg['output_scaling'])\n",
    "retinal_encoder.to(cfg['device'])\n",
    "\n",
    "phosphene_coords = cortex_models.get_visual_field_coordinates_probabilistically(params, n_phosphenes)\n",
    "simulator = get_simulator(cfg, phosphene_coords)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(retinal_encoder.parameters(), lr=0.0009)\n",
    "\n",
    "# Set deterministic algorithms off\n",
    "torch.use_deterministic_algorithms(False)\n",
    "\n",
    "for i in range(800):\n",
    "    # Generate random image and make non differentiable\n",
    "    batch = next(iter(trainloader))\n",
    "    random_image, contour = batch['image'].to(cfg['device']), batch['contour'].to(cfg['device'])\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    stimulation = retinal_encoder(random_image)\n",
    "    simulator.reset()\n",
    "    phosphenes = simulator(stimulation)\n",
    "    simulator.reset()\n",
    "    phosphene_centers = simulator.sample_centers(phosphenes)\n",
    "    \n",
    "    \n",
    "    # Define target\n",
    "    resized = resize(contour.float(), cfg['SPVsize'])\n",
    "    simulator.reset()\n",
    "    target = simulator.sample_centers(resized.mean(1, keepdim=True))\n",
    "    simulator.reset()\n",
    "    target_stimulus = simulator.sample_stimulus(resized.mean(1, keepdim=True)*cfg['output_scaling'])\n",
    "\n",
    "    # Calculate loss\n",
    "    # loss = loss_fn(phosphene_centers, target)\n",
    "    loss = loss_fn(stimulation, target_stimulus)\n",
    "\n",
    "    # Zero gradients, backward pass, and update weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # print(f'Epoch {i} Loss: {loss.item()}')\n",
    "        # show input image and phosphenes, and combined/overlayed image, target\n",
    "\n",
    "        fig, ax = plt.subplots(2, 4, figsize=(22, 12))\n",
    "        ax[0, 0].imshow(random_image[0].permute(1, 2, 0).detach().cpu().numpy(), cmap='gray')\n",
    "        ax[0, 0].axis('off')\n",
    "        ax[0, 0].set_title('Visual Input')\n",
    "\n",
    "        # phosphene image\n",
    "        ax[0, 1].imshow(phosphenes[0].detach().cpu().numpy(), cmap='gray')\n",
    "        ax[0, 1].axis('off')\n",
    "        ax[0, 1].set_title('Phosphenes')\n",
    "\n",
    "        # combined image\n",
    "        ax[0, 2].imshow(resized[0].permute(1, 2, 0).detach().cpu().numpy(), cmap='gray')\n",
    "        ax[0, 2].imshow(phosphenes[0].detach().cpu().numpy(), cmap='gray', alpha=0.5)\n",
    "        ax[0, 2].axis('off')\n",
    "        ax[0, 2].set_title('Combined Image')\n",
    "    \n",
    "        # target\n",
    "        simulator.reset()\n",
    "        out = simulator(target_stimulus)[0]\n",
    "        ax[0, 3].imshow(out.detach().cpu().numpy(), cmap='gray')\n",
    "        ax[0, 3].axis('off')\n",
    "        ax[0, 3].set_title('Target')\n",
    "\n",
    "        # 1,0 text block with training stats\n",
    "        ax[1, 0].text(0.1, 0.5, f'Epoch {i} Loss: {loss.item()}', fontsize=12, ha='left')\n",
    "        ax[1, 0].text(0.1, 0.4, f'Max Stimul: {stimulation.max().item()}', fontsize=12, ha='left')\n",
    "        ax[1, 0].text(0.1, 0.3, f'Max Target: {target_stimulus.max().item()}', fontsize=12, ha='left')\n",
    "        ax[1, 0].axis('off')\n",
    "        \n",
    "        # Create a square stimulation grid with a mask\n",
    "        stimulation_square = torch.zeros((reshape_square, reshape_square), device=cfg['device'])\n",
    "        stimulation_square.view(-1)[:N_PHOSPHENES] = stimulation[0]\n",
    "\n",
    "        stimulation_target_square = torch.zeros((reshape_square, reshape_square), device=cfg['device'])\n",
    "        stimulation_target_square.view(-1)[:N_PHOSPHENES] = target[0]\n",
    "\n",
    "        ax[1, 1].imshow(stimulation_square.detach().cpu().numpy(), cmap='gray', vmin=0, vmax=1.0000e-04)\n",
    "        ax[1, 1].set_title('Neural encoded Stimulation')\n",
    "        ax[1, 1].axis('off')\n",
    "\n",
    "        ax[1, 2].axis('off')\n",
    "\n",
    "        ax[1, 3].imshow(stimulation_target_square.cpu().numpy(), cmap='gray', vmin=0, vmax=1.0000e-04)\n",
    "        ax[1, 3].set_title('Target Stimulation')\n",
    "        ax[1, 3].axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
